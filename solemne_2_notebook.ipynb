{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe0d452",
   "metadata": {},
   "source": [
    "# Solemne 2 Fish´s Head and Tail detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9db4f5b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "import yaml\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e38fc-ba9f-4019-b172-2fb459e4dc65",
   "metadata": {},
   "source": [
    "### Clean names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de937e-fe68-47e1-8691-c3bb7c353c6d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "base_folder = \"content\"\n",
    "prefix = \"-\"\n",
    "for root, dirs, files in os.walk(base_folder):\n",
    "    for filename in files:\n",
    "        old_path = os.path.join(root, filename)\n",
    "    \n",
    "        if prefix not in filename:\n",
    "            continue\n",
    "    \n",
    "        new_name = filename.split(prefix, 1)[1]\n",
    "        new_path = os.path.join(root, new_name)\n",
    "    \n",
    "        if os.path.exists(new_path):\n",
    "            print(f\"Archive already exist, next: {new_name}\")\n",
    "            continue\n",
    "    \n",
    "        os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07becf78-9e65-4af2-abcc-34adf5dfc84d",
   "metadata": {},
   "source": [
    "### Create YOLO files structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7c8ce34-407b-46fb-a6ef-6598f3c87226",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"dataset_yolo/train/images\", exist_ok=True)\n",
    "os.makedirs(\"dataset_yolo/train/labels\", exist_ok=True)\n",
    "os.makedirs(\"dataset_yolo/val/images\", exist_ok=True)\n",
    "os.makedirs(\"dataset_yolo/val/labels\", exist_ok=True)\n",
    "os.makedirs(\"dataset_yolo/test/images\", exist_ok=True)\n",
    "os.makedirs(\"dataset_yolo/test/labels\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a2c28-4cf0-42e2-8aef-9d2167150665",
   "metadata": {},
   "source": [
    "### Obtain test, train and val images names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5603f333-4704-4968-a202-879c5855b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "singular_dir = \"singular_images\"\n",
    "singular_names = os.listdir(singular_dir)\n",
    "len_singular_names = len(singular_names)\n",
    "\n",
    "images_path = \"content/images\"\n",
    "labels_path = \"content/labels\"\n",
    "\n",
    "images_names = os.listdir(images_path)\n",
    "labels_names = os.listdir(labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ad86aba-5742-4557-a490-7f4ff910e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random(names, amount, seed):\n",
    "    random.seed(seed)\n",
    "    selected = random.sample(names, min(amount, len(names)))\n",
    "    remaining = list(set(names) - set(selected))\n",
    "    return selected, remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "831f93bc-9bad-4103-be33-7a6f3f21ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [0.75, 0.15]\n",
    "images_distribution = {\"train_list\": [], \"test_list\": [], \"val_list\": []}\n",
    "images_names = list(set(images_names) - set(singular_names))\n",
    "len_images_remaining = len(images_names)\n",
    "# Singular_images selection\n",
    "train_selected, remaining_names = select_random(singular_names, int(len_singular_names * percentages[0]), 1)\n",
    "images_distribution[\"train_list\"] = train_selected\n",
    "test_selected, remaining_names = select_random(remaining_names, int(len_singular_names * percentages[1]), 1)\n",
    "images_distribution[\"test_list\"] = test_selected\n",
    "images_distribution[\"val_list\"] = remaining_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b8ba134-ab70-41f4-a8ad-c71f76379cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribute the others images\n",
    "train_selected, remaining_names = select_random(images_names, int(len_images_remaining * percentages[0]), 1)\n",
    "images_distribution[\"train_list\"] += train_selected\n",
    "test_selected, remaining_names = select_random(remaining_names, int(len_images_remaining * percentages[1]), 1)\n",
    "images_distribution[\"test_list\"] += test_selected\n",
    "images_distribution[\"val_list\"] += remaining_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f5dd40-db69-4fc8-94a5-229eee7670e8",
   "metadata": {},
   "source": [
    "### Move Files based on generated list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4651f719-1d76-4f54-a331-9f4104ef68a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files(file_list, split):\n",
    "    for img_name in file_list:\n",
    "        name_base, ext = os.path.splitext(img_name)\n",
    "        label_name = f\"{name_base}.txt\"\n",
    "\n",
    "        img_src = os.path.join(images_path, img_name)\n",
    "        lbl_src = os.path.join(labels_path, label_name)\n",
    "\n",
    "        img_dst = os.path.join(\"dataset_yolo\", split, \"images\", img_name)\n",
    "        lbl_dst = os.path.join(\"dataset_yolo\", split, \"labels\", label_name)\n",
    "\n",
    "        if os.path.exists(img_src):\n",
    "            shutil.move(img_src, img_dst)\n",
    "        else:\n",
    "            print(f\"Image not found: {img_name}\")\n",
    "\n",
    "        if os.path.exists(lbl_src):\n",
    "            shutil.move(lbl_src, lbl_dst)\n",
    "        else:\n",
    "            print(f\"Label not found: {label_name}\")\n",
    "\n",
    "move_files(images_distribution[\"train_list\"], \"train\")\n",
    "move_files(images_distribution[\"test_list\"], \"test\")\n",
    "move_files(images_distribution[\"val_list\"], \"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c092b19",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d94e9e7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed fixed: 0\n"
     ]
    }
   ],
   "source": [
    "def fix_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Seed fixed: {seed}\")\n",
    "\n",
    "fix_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3405c76",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a1eec",
   "metadata": {},
   "source": [
    "### Learning rate Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c1aaf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data_yaml = \"data.yaml\"\n",
    "base_model = \"yolov8n.yaml\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "learning_rates= [0.00001, 0.00005, 0.0001, 0.0005, 0.001]\n",
    "results_list= []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = YOLO(base_model)\n",
    "\n",
    "    results = model.train(\n",
    "        data=data_yaml,       \n",
    "        epochs=30,             \n",
    "        imgsz=300,\n",
    "        batch=15,\n",
    "        device=device,              \n",
    "        pretrained=False,\n",
    "        optimizer=\"Adam\",\n",
    "        lr0=lr,\n",
    "        project=\"lr_search_results\",\n",
    "        name=f\"lr_{lr}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4802ee-8e89-4ee8-9ebe-a980d8b8073b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 'dataset_yolo/train/images', 'val': 'dataset_yolo/val/images', 'test': 'dataset_yolo/test/images', 'nc': 2, 'names': ['head', 'tail']}\n",
      "\n",
      "LR=1e-05 | Fold 1/3\n",
      "Train_files: ['/home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/dataset_yolo/train/images/seq_0004_00033.jpeg', '/home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/dataset_yolo/train/images/seq_0006_01258.jpeg', '/home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/dataset_yolo/train/images/seq_0006_00546.jpeg', '/home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/dataset_yolo/train/images/seq_0002_00194.jpeg', '/home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/dataset_yolo/train/images/seq_0006_00496.jpeg', '/home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/dataset_yolo/train/images/seq_0002_00259.jpeg', '/home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/dataset_yolo/train/images/seq_0002_00058.jpeg', '/home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/dataset_yolo/train/images/seq_0006_01057.jpeg', '/home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/dataset_yolo/train/images/seq_0001_00182.jpeg', '/home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/dataset_yolo/train/images/seq_0006_00231.jpeg']\n",
      "New https://pypi.org/project/ultralytics/8.3.221 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.213 🚀 Python-3.12.3 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=15, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=kfold_lr_1e-05_fold_0/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=300, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=1e-05, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=lr1e-05_fold05, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=False, profile=False, project=kfold_lr, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/kfold_lr/lr1e-05_fold05, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 16.8MB/s 0.3s.3s<0.1s7s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "WARNING ⚠️ imgsz=[300] must be multiple of max stride 32, updating to [320]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 320.9±87.6 MB/s, size: 269.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/dataset_yolo/train/labels... 658 images, 75 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 658/658 1.2Kit/s 0.6s<0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/dataset_yolo/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 326.1±85.0 MB/s, size: 269.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/dataset_yolo/train/labels... 329 images, 40 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 329/329 8.7it/s 37.8ss<0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/dataset_yolo/train/labels.cache\n",
      "Plotting labels to /home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/kfold_lr/lr1e-05_fold05/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=1e-05, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.00046875), 63 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/vinbu/University/Semester_8/Unit_2_Ai/AI_Solemne_2/kfold_lr/lr1e-05_fold05\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/30     0.605G      3.055      4.008      1.299         49        320: 100% ━━━━━━━━━━━━ 44/44 5.7it/s 7.7s6.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 5.5it/s 2.0s0.2s\n",
      "                   all        329        654    0.00365     0.0685    0.00269    0.00114\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/30     0.627G      2.486      2.831      1.094         35        320: 100% ━━━━━━━━━━━━ 44/44 8.5it/s 5.2s<5.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ━━━━━━━━━━╸─ 10/11 7.1it/s 1.4s<0.1sWARNING ⚠️ NMS time limit 3.450s exceeded\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 0.3it/s 38.9s\n",
      "                   all        329        654     0.0259       0.69      0.198     0.0711\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/30     0.627G      2.457      2.467      1.083         56        320: 100% ━━━━━━━━━━━━ 44/44 9.5it/s 4.6s0.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 7.3it/s 1.5s0:48\n",
      "                   all        329        654      0.502      0.204      0.297      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/30     0.627G      2.433      2.328      1.078         43        320: 100% ━━━━━━━━━━━━ 44/44 9.5it/s 4.7s<2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 6.5it/s 1.7s0.2s\n",
      "                   all        329        654      0.346      0.429      0.325      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/30     0.627G      2.385      2.253      1.072         35        320: 100% ━━━━━━━━━━━━ 44/44 9.7it/s 4.6s6.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 6.1it/s 1.8s0.5s\n",
      "                   all        329        654      0.335      0.495      0.337      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/30     0.627G      2.337      2.194       1.08         34        320: 100% ━━━━━━━━━━━━ 44/44 9.6it/s 4.6s<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 6.9it/s 1.6s0.1s\n",
      "                   all        329        654      0.359      0.531      0.349      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/30     0.627G      2.386      2.167      1.058         35        320: 100% ━━━━━━━━━━━━ 44/44 9.4it/s 4.7s<2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 6.1it/s 1.8s0.2s\n",
      "                   all        329        654      0.379      0.549      0.367      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/30     0.629G      2.398       2.16      1.076         55        320: 100% ━━━━━━━━━━━━ 44/44 9.6it/s 4.6s5.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 6.4it/s 1.7s0.5s\n",
      "                   all        329        654      0.392      0.562      0.376      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/30     0.646G      2.312      2.099      1.044         40        320: 100% ━━━━━━━━━━━━ 44/44 8.8it/s 5.0s<1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 5.6it/s 2.0s0.2s\n",
      "                   all        329        654      0.398      0.563      0.385      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/30     0.646G       2.33      2.069      1.062         49        320: 100% ━━━━━━━━━━━━ 44/44 8.6it/s 5.1s<3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 0.3it/s 39.2s0.2s\n",
      "                   all        329        654      0.405      0.561      0.393      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/30     0.646G      2.305      2.083      1.056         65        320: 100% ━━━━━━━━━━━━ 44/44 10.0it/s 4.4s.1ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 6.8it/s 1.6s0:50\n",
      "                   all        329        654      0.403      0.569      0.404      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/30     0.664G      2.341      2.073      1.065         44        320: 100% ━━━━━━━━━━━━ 44/44 9.6it/s 4.6s<2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 6.5it/s 1.7s0.2s\n",
      "                   all        329        654      0.399      0.577      0.409       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/30     0.664G      2.301       2.02      1.052         35        320: 100% ━━━━━━━━━━━━ 44/44 9.8it/s 4.5s<4.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 7.3it/s 1.5s0.1s\n",
      "                   all        329        654      0.406       0.58      0.416      0.162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/30     0.664G      2.313      2.067      1.044         28        320: 100% ━━━━━━━━━━━━ 44/44 9.7it/s 4.5s:29:30\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 7.3it/s 1.5s1.0s\n",
      "                   all        329        654      0.404       0.59      0.421      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/30     0.664G       2.32      2.038      1.043         47        320: 100% ━━━━━━━━━━━━ 44/44 9.5it/s 4.6s<1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 7.1it/s 1.6s0.1s\n",
      "                   all        329        654      0.402      0.595      0.423      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/30     0.682G      2.289      2.021      1.048         38        320: 100% ━━━━━━━━━━━━ 44/44 9.8it/s 4.5s<3.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 11/11 7.1it/s 1.6s0.1s\n",
      "                   all        329        654      0.412      0.568      0.423      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/30     0.682G      2.393      2.064       1.04         39        320: 16% ━╸────────── 7/44 4.9it/s 38.3s<7.6s"
     ]
    }
   ],
   "source": [
    "data_yaml = \"data.yaml\"\n",
    "base_model = \"yolov8n.pt\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "learning_rates = [0.00001, 0.00005, 0.0001]\n",
    "k_folds = 3\n",
    "\n",
    "with open(data_yaml, 'r') as f:\n",
    "    data_dict = yaml.safe_load(f)\n",
    "print(data_dict)\n",
    "\n",
    "images_names = os.listdir(data_dict[\"train\"])\n",
    "images= []\n",
    "for img in images_names:\n",
    "    images.append(data_dict[\"train\"]+f\"/{img}\")\n",
    "\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(images)):\n",
    "        print(f\"\\nLR={lr} | Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "        train_files = [images[i] for i in train_idx]\n",
    "        val_files = [images[i] for i in val_idx]\n",
    "\n",
    "        fold_folder = f\"kfold_lr_{lr}_fold_{fold}\"\n",
    "        os.makedirs(fold_folder, exist_ok=True)\n",
    "        train_file = os.path.join(fold_folder, \"train.txt\")\n",
    "        val_file = os.path.join(fold_folder, \"val.txt\")\n",
    "        \n",
    "        train_files_abs = [os.path.abspath(f) for f in train_files]\n",
    "        val_files_abs = [os.path.abspath(f) for f in val_files]\n",
    "\n",
    "        print(f\"Train_files: {train_files_abs[:10]}\")\n",
    "\n",
    "        with open(train_file, \"w\") as f:\n",
    "            f.write(\"\\n\".join(train_files_abs))\n",
    "        with open(val_file, \"w\") as f:\n",
    "            f.write(\"\\n\".join(val_files_abs))\n",
    "\n",
    "        temp_yaml = os.path.join(fold_folder, \"data.yaml\")\n",
    "        temp_data = data_dict.copy()\n",
    "        temp_data[\"train\"] = os.path.abspath(train_file)\n",
    "        temp_data[\"val\"] = os.path.abspath(val_file)\n",
    "\n",
    "        with open(temp_yaml, \"w\") as f:\n",
    "            yaml.dump(temp_data, f)\n",
    "\n",
    "        model = YOLO(base_model)\n",
    "\n",
    "        results = model.train(\n",
    "            data=temp_yaml,\n",
    "            epochs=30,\n",
    "            imgsz=300,\n",
    "            batch=15,\n",
    "            device=device,\n",
    "            pretrained=False,\n",
    "            optimizer=\"Adam\",\n",
    "            lr0=lr,\n",
    "            project=\"kfold_lr\",\n",
    "            name=f\"lr{lr}_fold{fold}\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d128a450-2131-4083-a24d-de77c9c77e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yolov8-env)",
   "language": "python",
   "name": "yolov8-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
